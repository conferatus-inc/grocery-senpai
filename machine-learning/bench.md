# Бенчи и прочее
Была проанализирована производительность модели, обучаемой с помощью линейной регрессии. 
## Условия
Использовался интерпретатор python3 3.11, тактовая частота процессора (AMD Ryzen 4600H) ок. 3 ггц. Вычисления однопоточные.
Для замеров использовалась функция perf_counter() стандартного модуля time.

## Тайм комплексити
Для обучения: O((f+1)csE), f - колво признаков, c - кол-во классов, s - сколько сэмплов, E - эпох для градиентного спуска. В целом, вся производительность упирается как раз таки в градиентный спуск.
Для предикта: O((f+1)cs).

## Мемори комплексити
Пока что О(бесконечность), но на самом деле дополнительно выходит около O((f+1)cs) и для обучения, и для предикта. В текущем виде данные занимают пренебрежимо мало памяти.

## Результат 
Обучение для одной категории за ~200 дней и последующий предикт занимают около 0.0035 сек. Соответственно, обучение для, например, 500 категорий (для которых, напомним, обучается 500 моделей) займет около 1.8 секунд.
При грамотной реализации модели на языке Kotlin (однозначно быстрее чем интерпретируемый питон) и подборе параметров, на современном мобильном устройстве предполагается результат не более чем в 2-3 раза хуже.

При таком времени вычислений (которые, к тому же, не всегда будут запускаться, только при обновлении списка продуктов) влияние на батарею предполагается на уровне погрешности.
